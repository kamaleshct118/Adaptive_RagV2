{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bef1f74f",
      "metadata": {},
      "source": [
        "# üè• Offline Vector Indexing Pipeline (Medical Education)\n",
        "\n",
        "## üìã Overview\n",
        "This notebook is the **Preprocessing Factory** for the Adaptive RAG system.\n",
        "It transforms raw medical documents (PDFs/Images) into a mathematical **Vector Index** that the main AI system can search.\n",
        "\n",
        "### üîÑ Pipeline Workflow\n",
        "1.  **Input**: Raw PDF/Image files.\n",
        "2.  **OCR**: Extract text using Tesseract.\n",
        "3.  **Cleaning**: Normalize and remove noise.\n",
        "4.  **Chunking**: Split text into overlapping sliding windows.\n",
        "5.  **Embedding**: Convert text chunks into Vectors (Numbers).\n",
        "6.  **Indexing**: Build a FAISS Vector Database.\n",
        "7.  **Output**: Save artifacts (`index.faiss`, `metadata.pkl`, `texts.pkl`).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7664a320",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Step 1: Install Dependencies\n",
        "**What it does**:\n",
        "- Installs OCR tools (Tesseract, Poppler).\n",
        "- Installs Python libraries for PDF processing (`pdf2image`), Vector Search (`faiss-cpu`), and embeddings (`sentence-transformers`).\n",
        "\n",
        "**Input**: None\n",
        "**Output**: System tools and Python libraries installed.\n",
        "**Role**: Infrastructure Setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71de33c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üì¶ Install Dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y poppler-utils tesseract-ocr\n",
        "!pip install -q sentence-transformers faiss-cpu pytesseract pdf2image opencv-python numpy tqdm\n",
        "\n",
        "print(\"‚úÖ Libraries installed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d0ce4d3",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Step 2: Environment Setup\n",
        "**What it does**:\n",
        "- Creates a clean `./vector_store` directory to save our results.\n",
        "- Checks if OCR tools are working correctly.\n",
        "\n",
        "**Input**: None\n",
        "**Output**: A clean directory ready for data.\n",
        "**Role**: Workspace Preparation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9a827ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚öôÔ∏è Environment Setup\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "OUTPUT_DIR = './vector_store'\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR) # Clean start\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "print(f\"üìÇ Created output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "try:\n",
        "    import pytesseract\n",
        "    pytesseract.get_tesseract_version()\n",
        "    print(\"‚úÖ Tesseract OCR is available.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Tesseract OCR not found. Please verify installation.\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8e2386",
      "metadata": {},
      "source": [
        "## üî¢ Step 3: Input Configuration\n",
        "**What it does**:\n",
        "- Asks you how many files you want to process.\n",
        "- Sets up the batch size.\n",
        "\n",
        "**Input**: User types a number (e.g., \"3\").\n",
        "**Output**: `num_documents` variable set.\n",
        "**Role**: Job Configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f53e96a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üî¢ Input Count\n",
        "try:\n",
        "    num_documents = int(input(\"Enter number of documents to process: \"))\n",
        "    print(f\"üìÑ We will process {num_documents} documents.\")\n",
        "except ValueError:\n",
        "    num_documents = 1\n",
        "    print(\"‚ö†Ô∏è Invalid input. Defaulting to 1 document.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391de8eb",
      "metadata": {},
      "source": [
        "## üì§ Step 4: Upload Documents\n",
        "**What it does**:\n",
        "- Opens the Google Colab file picker.\n",
        "- Allows you to upload PDF, JPG, or PNG files.\n",
        "\n",
        "**Input**: Files from your computer.\n",
        "**Output**: Files saved to Colab runtime.\n",
        "**Role**: Data Ingestion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eccd1b6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üì§ Upload Files\n",
        "from google.colab import files\n",
        "\n",
        "print(f\"Please upload {num_documents} file(s) (PDF, JPG, PNG)...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "source_files = list(uploaded.keys())\n",
        "if len(source_files) == 0: raise ValueError(\"No files uploaded Exiting.\")\n",
        "\n",
        "print(\"\\nFiles to be processed:\")\n",
        "for i, f in enumerate(source_files): print(f\"{i}: {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54a0b1a9",
      "metadata": {},
      "source": [
        "## üîç Step 5: OCR (Text Extraction)\n",
        "**What it does**:\n",
        "- Converts PDFs into images.\n",
        "- Uses Tesseract OCR to read text from those images.\n",
        "- Handles both PDFs and raw Images (JPG/PNG).\n",
        "\n",
        "**Input**: Raw files (PDF/Image).\n",
        "**Output**: Raw text strings for each document.\n",
        "**Role**: Digitization (converting pixels to text).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d54ce3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üîç Run OCR\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "documents = [] # [{'doc_id', 'source', 'raw_text'}]\n",
        "print(\"üöÄ Starting OCR extraction...\")\n",
        "\n",
        "for doc_idx, filename in enumerate(source_files):\n",
        "    print(f\"\\nüìÑ Processing {filename} ({doc_idx+1}/{len(source_files)})...\")\n",
        "    full_text = \"\"\n",
        "    file_ext = filename.split('.')[-1].lower()\n",
        "    \n",
        "    try:\n",
        "        if file_ext == 'pdf':\n",
        "            images = convert_from_path(filename)\n",
        "            for image in images:\n",
        "                full_text += pytesseract.image_to_string(image) + \"\\n\"\n",
        "        elif file_ext in ['jpg', 'jpeg', 'png']:\n",
        "            full_text += pytesseract.image_to_string(Image.open(filename))\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Skipping unsupported file: {filename}\")\n",
        "            continue\n",
        "            \n",
        "        documents.append({\"doc_id\": doc_idx, \"source\": filename, \"raw_text\": full_text})\n",
        "        print(f\"   ‚úÖ Extracted {len(full_text)} characters.\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "print(f\"\\nüèÅ OCR Complete. Processed {len(documents)} docs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1704be96",
      "metadata": {},
      "source": [
        "## üßπ Step 6: Noise Removal\n",
        "**What it does**:\n",
        "- Normalizes text (lowercasing, unicode fixing).\n",
        "- Removes artifacts like \"Page 1 of 5\".\n",
        "- Removes excess whitespace.\n",
        "\n",
        "**Input**: Raw OCR text.\n",
        "**Output**: Clean, high-quality text.\n",
        "**Role**: Data Cleaning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d95e2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üßπ Clean Text\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'page \\d+ of \\d+', '', text)\n",
        "    text = re.sub(r'page \\d+', '', text)\n",
        "    return text\n",
        "\n",
        "print(\"Cleaning text...\\n\")\n",
        "for doc in documents:\n",
        "    doc['clean_text'] = normalize_text(doc['raw_text'])\n",
        "    print(f\"Doc {doc['doc_id']}: reduced {len(doc['raw_text'])} -> {len(doc['clean_text'])} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5672cb4d",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Step 7: Chunking (Sliding Window)\n",
        "**What it does**:\n",
        "- Splits long documents into smaller segments (Chunks).\n",
        "- Uses **Overlap** to ensure context isn't cut off at the edge.\n",
        "\n",
        "**Input**: Config (Chunk Size=400 chars, Overlap=80 chars).\n",
        "**Output**: List of Chunk objects.\n",
        "**Role**: Granularity Control (preparing text for the Embedding Model).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2e4688",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ‚úÇÔ∏è Execute Chunking\n",
        "CHUNK_SIZE = 400\n",
        "CHUNK_OVERLAP = 80\n",
        "\n",
        "chunks = []\n",
        "chunk_counter = 0\n",
        "\n",
        "for doc in documents:\n",
        "    text = doc['clean_text']\n",
        "    for i in range(0, len(text), CHUNK_SIZE - CHUNK_OVERLAP):\n",
        "        chunk_text = text[i : i + CHUNK_SIZE]\n",
        "        if len(chunk_text) < 50: continue # Skip noise\n",
        "        \n",
        "        chunks.append({\n",
        "            \"chunk_id\": chunk_counter,\n",
        "            \"doc_id\": doc['doc_id'],\n",
        "            \"text\": chunk_text,\n",
        "            \"source\": doc['source'],\n",
        "            \"position\": i\n",
        "        })\n",
        "        chunk_counter += 1\n",
        "\n",
        "print(f\"‚úÖ Generated {len(chunks)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c731ab",
      "metadata": {},
      "source": [
        "## üß† Step 8: Load Embedding Model\n",
        "**What it does**:\n",
        "- Loads `sentence-transformers/all-MiniLM-L6-v2`.\n",
        "- This model converts text into 384-dimensional vectors.\n",
        "**Critical**: This MUST match the model used in the Inference Notebook.\n",
        "\n",
        "**Input**: Model Name.\n",
        "**Output**: Loaded Model in memory.\n",
        "**Role**: Neural Encoder Loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fc8535",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üß† Load Model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "print(f\"Loading model: {MODEL_NAME}...\")\n",
        "embedding_model = SentenceTransformer(MODEL_NAME)\n",
        "print(\"‚úÖ Model loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929ee4c1",
      "metadata": {},
      "source": [
        "## üî¢ Step 9: Generate Embeddings\n",
        "**What it does**:\n",
        "- Passes all text chunks through the Neural Network.\n",
        "- Returns a matrix of floating point numbers.\n",
        "\n",
        "**Input**: List of text strings.\n",
        "**Output**: Numpy array of shape `(Num_Chunks, 384)`.\n",
        "**Role**: Vectorization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54561fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üî¢ Compute Embeddings\n",
        "import numpy as np\n",
        "chunk_texts = [c['text'] for c in chunks]\n",
        "print(f\"Encoding {len(chunk_texts)} chunks...\")\n",
        "embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "embeddings = embeddings.astype(np.float32)\n",
        "print(f\"‚úÖ Embeddings shape: {embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa0c4bc",
      "metadata": {},
      "source": [
        "## üìö Step 10: Create FAISS Index\n",
        "**What it does**:\n",
        "- Creates a structural index optimized for fast L2 (Euclidean) distance search.\n",
        "- Adds the vectors to this index.\n",
        "\n",
        "**Input**: Embeddings Matrix.\n",
        "**Output**: Populated FAISS Index.\n",
        "**Role**: Database Creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cbec16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üìö Build Index\n",
        "import faiss\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "print(f\"‚úÖ FAISS Index created. Total vectors: {index.ntotal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309ad650",
      "metadata": {},
      "source": [
        "## üóÇÔ∏è Step 11: Configure Metadata\n",
        "**What it does**:\n",
        "- Creates a \"Sidecar\" dictionary that links every Vector ID back to its original Text and Source File.\n",
        "- FAISS stores numbers; this stores the actual info.\n",
        "\n",
        "**Input**: Chunk list.\n",
        "**Output**: `metadata_store` and `text_store` dictionaries.\n",
        "**Role**: Data Mapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1744183",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üóÇÔ∏è Prepare Meta Stores\n",
        "metadata_store = {}\n",
        "text_store = {}\n",
        "for i, chunk in enumerate(chunks):\n",
        "    c_id = chunk['chunk_id']\n",
        "    metadata_store[c_id] = { \"doc_id\": chunk['doc_id'], \"source\": chunk['source'], \"position\": chunk['position'] }\n",
        "    text_store[c_id] = chunk['text']\n",
        "print(f\"‚úÖ Prepared metadata for {len(metadata_store)} items.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee1168b",
      "metadata": {},
      "source": [
        "## üíæ Step 12: Save to Disk\n",
        "**What it does**:\n",
        "- Serializes (saves) all artifacts to the `./vector_store` folder.\n",
        "- Zips the folder for easy download.\n",
        "\n",
        "**Input**: Index, Dictionaries, Config.\n",
        "**Output**: `vector_store_backup.zip`.\n",
        "**Role**: Persistence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa673dcf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title üíæ Save & Zip\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "index_path = os.path.join(OUTPUT_DIR, 'index.faiss')\n",
        "metadata_path = os.path.join(OUTPUT_DIR, 'metadata.pkl')\n",
        "texts_path = os.path.join(OUTPUT_DIR, 'texts.pkl')\n",
        "\n",
        "faiss.write_index(index, index_path)\n",
        "with open(metadata_path, 'wb') as f: pickle.dump(metadata_store, f)\n",
        "with open(texts_path, 'wb') as f: pickle.dump(text_store, f)\n",
        "\n",
        "print(\"‚úÖ All artifacts saved.\")\n",
        "shutil.make_archive('vector_store_backup', 'zip', OUTPUT_DIR)\n",
        "print(\"üì¶ Created 'vector_store_backup.zip' for download.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
