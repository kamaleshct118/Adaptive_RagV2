{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bef1f74f",
      "metadata": {},
      "source": [
        "# üè• Offline Vector Indexing Pipeline (Medical Education)\n",
        "\n",
        "## üìã Overview\n",
        "This notebook is the **Preprocessing Factory** for the Adaptive RAG system.\n",
        "It transforms raw medical documents (PDFs/Images) into a mathematical **Vector Index** that the main AI system can search.\n",
        "\n",
        "### üîÑ Pipeline Workflow\n",
        "1.  **Input**: Raw PDF/Image files.\n",
        "2.  **OCR**: Extract text using Tesseract.\n",
        "3.  **Cleaning**: Normalize and remove noise.\n",
        "4.  **Chunking**: Split text into overlapping sliding windows.\n",
        "5.  **Embedding**: Convert text chunks into Vectors (Numbers).\n",
        "6.  **Indexing**: Build a FAISS Vector Database.\n",
        "7.  **Output**: Save artifacts (`index.faiss`, `metadata.pkl`, `texts.pkl`).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7664a320",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Step 1: Install Dependencies\n",
        "**What it does**:\n",
        "- Installs OCR tools (Tesseract, Poppler).\n",
        "- Installs Python libraries for PDF processing (`pdf2image`), Vector Search (`faiss-cpu`), and embeddings (`sentence-transformers`).\n",
        "\n",
        "**Input**: None\n",
        "**Output**: System tools and Python libraries installed.\n",
        "**Role**: Infrastructure Setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a71de33c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Skipping apt-get (Local Environment detected).\n",
            "Ensure Tesseract OCR and Poppler are installed on your system.\n",
            "Run: pip install -r requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# @title üì¶ Install Dependencies\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    !apt-get update -qq\n",
        "    !apt-get install -y poppler-utils tesseract-ocr\n",
        "    !pip install -q faiss-cpu gradio ipykernel jupyter numpy opencv-python pdf2image pickle-mixin pillow pytesseract requests scikit-learn sentence-transformers tqdm\n",
        "    print(\"‚úÖ Libraries installed successfully (Colab).\")\n",
        "else:\n",
        "    print(\"‚úÖ Skipping apt-get (Local Environment detected).\")\n",
        "    print(\"Ensure Tesseract OCR and Poppler are installed on your system.\")\n",
        "    print(\"Run: pip install -r requirements.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d0ce4d3",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Step 2: Environment Setup\n",
        "**What it does**:\n",
        "- Creates a clean `./vector_store` directory to save our results.\n",
        "- Checks if OCR tools are working correctly.\n",
        "\n",
        "**Input**: None\n",
        "**Output**: A clean directory ready for data.\n",
        "**Role**: Workspace Preparation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e9a827ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Created output directory: ./vector_store\n",
            "üîç Found Conda Tesseract at: v:\\anaconda3\\envs\\venv\\Library\\bin\\tesseract.exe\n",
            "‚úÖ Tesseract OCR is available (Version: 5.5.1).\n"
          ]
        }
      ],
      "source": [
        "# @title ‚öôÔ∏è Environment Setup\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "OUTPUT_DIR = './vector_store'\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR) # Clean start\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "print(f\"üìÇ Created output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# --- TESSERACT SETUP ---\n",
        "try:\n",
        "    import pytesseract\n",
        "    # Check for Conda-installed Tesseract\n",
        "    # Typically in <Env>/Library/bin/tesseract.exe on Windows\n",
        "    conda_prefix = sys.prefix\n",
        "    conda_tesseract = os.path.join(conda_prefix, 'Library', 'bin', 'tesseract.exe')\n",
        "    \n",
        "    if os.path.exists(conda_tesseract):\n",
        "        pytesseract.pytesseract.tesseract_cmd = conda_tesseract\n",
        "        print(f\"üîç Found Conda Tesseract at: {conda_tesseract}\")\n",
        "    elif os.name == 'nt':\n",
        "        # Fallback to standard install locations\n",
        "        possible_paths = [\n",
        "            r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe',\n",
        "            r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe',\n",
        "            os.path.join(os.getenv('LOCALAPPDATA', ''), r'Tesseract-OCR\\tesseract.exe')\n",
        "        ]\n",
        "        for p in possible_paths:\n",
        "            if os.path.exists(p):\n",
        "                pytesseract.pytesseract.tesseract_cmd = p\n",
        "                print(f\"üîç Found System Tesseract at: {p}\")\n",
        "                break\n",
        "                \n",
        "    version = pytesseract.get_tesseract_version()\n",
        "    print(f\"‚úÖ Tesseract OCR is available (Version: {version}).\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Tesseract OCR not found. Please run: conda install -c conda-forge tesseract\")\n",
        "    print(f\"Details: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8e2386",
      "metadata": {},
      "source": [
        "## üî¢ Step 3: Input Configuration\n",
        "**What it does**:\n",
        "- Asks you how many files you want to process.\n",
        "- Sets up the batch size.\n",
        "\n",
        "**Input**: User types a number (e.g., \"3\").\n",
        "**Output**: `num_documents` variable set.\n",
        "**Role**: Job Configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2f53e96a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ We will process 6 documents.\n"
          ]
        }
      ],
      "source": [
        "# @title üî¢ Input Count\n",
        "try:\n",
        "    num_documents = int(input(\"Enter number of documents to process: \"))\n",
        "    print(f\"üìÑ We will process {num_documents} documents.\")\n",
        "except ValueError:\n",
        "    num_documents = 1\n",
        "    print(\"‚ö†Ô∏è Invalid input. Defaulting to 1 document.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391de8eb",
      "metadata": {},
      "source": [
        "## üì§ Step 4: Upload Documents\n",
        "**What it does**:\n",
        "- Opens the Google Colab file picker.\n",
        "- Allows you to upload PDF, JPG, or PNG files.\n",
        "\n",
        "**Input**: Files from your computer.\n",
        "**Output**: Files saved to Colab runtime.\n",
        "**Role**: Data Ingestion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eccd1b6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíª Local Environment detected. Scanning './raw_documents' folder...\n",
            "\n",
            "Files to be processed:\n",
            "0: ./raw_documents\\bacterial.pdf\n",
            "1: ./raw_documents\\comon_overview.pdf\n",
            "2: ./raw_documents\\fungal.pdf\n",
            "3: ./raw_documents\\parasitic_infection.pdf\n",
            "4: ./raw_documents\\viral.pdf\n"
          ]
        }
      ],
      "source": [
        "# @title üì§ Upload Files (Hybrid)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(f\"Please upload {num_documents} file(s) (PDF, JPG, PNG)...\")\n",
        "    uploaded = files.upload()\n",
        "    source_files = list(uploaded.keys())\n",
        "except ImportError:\n",
        "    import os\n",
        "    print(\"üíª Local Environment detected. Scanning './raw_documents' folder...\")\n",
        "    input_dir = './raw_documents'\n",
        "    if not os.path.exists(input_dir):\n",
        "        os.makedirs(input_dir)\n",
        "        print(f\"‚ö†Ô∏è Created {input_dir}. Please put your files there and re-run.\")\n",
        "        source_files = []\n",
        "    else:\n",
        "        source_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.pdf', '.jpg', '.jpeg', '.png'))]\n",
        "        source_files = [os.path.join(input_dir, f) for f in source_files]\n",
        "\n",
        "if len(source_files) == 0:\n",
        "    print(f\"‚ö†Ô∏è No files found. Please upload to Colab or place files in './raw_documents' locally.\")\n",
        "else:\n",
        "    print(\"\\nFiles to be processed:\")\n",
        "    for i, f in enumerate(source_files): print(f\"{i}: {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54a0b1a9",
      "metadata": {},
      "source": [
        "## üîç Step 5: OCR (Text Extraction)\n",
        "**What it does**:\n",
        "- Converts PDFs into images.\n",
        "- Uses Tesseract OCR to read text from those images.\n",
        "- Handles both PDFs and raw Images (JPG/PNG).\n",
        "\n",
        "**Input**: Raw files (PDF/Image).\n",
        "**Output**: Raw text strings for each document.\n",
        "**Role**: Digitization (converting pixels to text).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f4d54ce3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting OCR extraction...\n",
            "\n",
            "üìÑ Processing ./raw_documents\\bacterial.pdf (1/5)...\n",
            "   ‚úÖ Extracted 41795 characters.\n",
            "\n",
            "üìÑ Processing ./raw_documents\\comon_overview.pdf (2/5)...\n",
            "   ‚úÖ Extracted 27768 characters.\n",
            "\n",
            "üìÑ Processing ./raw_documents\\fungal.pdf (3/5)...\n",
            "   ‚úÖ Extracted 10284 characters.\n",
            "\n",
            "üìÑ Processing ./raw_documents\\parasitic_infection.pdf (4/5)...\n",
            "   ‚úÖ Extracted 86982 characters.\n",
            "\n",
            "üìÑ Processing ./raw_documents\\viral.pdf (5/5)...\n",
            "   ‚úÖ Extracted 150177 characters.\n",
            "\n",
            "üèÅ OCR Complete. Processed 5 docs.\n"
          ]
        }
      ],
      "source": [
        "# @title üîç Run OCR\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "documents = [] # [{'doc_id', 'source', 'raw_text'}]\n",
        "print(\"üöÄ Starting OCR extraction...\")\n",
        "\n",
        "for doc_idx, filename in enumerate(source_files):\n",
        "    print(f\"\\nüìÑ Processing {filename} ({doc_idx+1}/{len(source_files)})...\")\n",
        "    full_text = \"\"\n",
        "    file_ext = filename.split('.')[-1].lower()\n",
        "    \n",
        "    try:\n",
        "        if file_ext == 'pdf':\n",
        "            # Assuming poppler is in PATH (installed via Conda)\n",
        "            images = convert_from_path(filename)\n",
        "            \n",
        "            for image in images:\n",
        "                full_text += pytesseract.image_to_string(image) + \"\\n\"\n",
        "        elif file_ext in ['jpg', 'jpeg', 'png']:\n",
        "            full_text += pytesseract.image_to_string(Image.open(filename))\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Skipping unsupported file: {filename}\")\n",
        "            continue\n",
        "            \n",
        "        documents.append({\"doc_id\": doc_idx, \"source\": filename, \"raw_text\": full_text})\n",
        "        print(f\"   ‚úÖ Extracted {len(full_text)} characters.\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error: {e}\")\n",
        "        if \"poppler\" in str(e).lower():\n",
        "             print(\"   üí° TIP: Ensure Poppler is installed in your Conda environment (conda install -c conda-forge poppler).\")\n",
        "\n",
        "print(f\"\\nüèÅ OCR Complete. Processed {len(documents)} docs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa5c64c3",
      "metadata": {},
      "source": [
        "## üíæ Step 5a: Save Extracted Text (Debug)\n",
        "**What it does**: Saves the raw OCR text to `.txt` files in `./extracted_texts` so you can inspect them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8e4599be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving extracted text to ./extracted_texts...\n",
            "   üìù Saved: bacterial.pdf.txt\n",
            "   üìù Saved: comon_overview.pdf.txt\n",
            "   üìù Saved: fungal.pdf.txt\n",
            "   üìù Saved: parasitic_infection.pdf.txt\n",
            "   üìù Saved: viral.pdf.txt\n",
            "\n",
            "‚úÖ Text saved for inspection.\n"
          ]
        }
      ],
      "source": [
        "# @title üíæ Save Extracted Text\n",
        "import os\n",
        "\n",
        "DEBUG_DIR = './extracted_texts'\n",
        "if not os.path.exists(DEBUG_DIR):\n",
        "    os.makedirs(DEBUG_DIR)\n",
        "\n",
        "print(f\"üíæ Saving extracted text to {DEBUG_DIR}...\")\n",
        "for doc in documents:\n",
        "    filename = os.path.basename(doc['source']) + \".txt\"\n",
        "    save_path = os.path.join(DEBUG_DIR, filename)\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(doc['raw_text'])\n",
        "    print(f\"   üìù Saved: {filename}\")\n",
        "\n",
        "print(\"\\n‚úÖ Text saved for inspection.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1704be96",
      "metadata": {},
      "source": [
        "## üßπ Step 6: Noise Removal\n",
        "**What it does**:\n",
        "- Normalizes text (lowercasing, unicode fixing).\n",
        "- Removes artifacts like \"Page 1 of 5\".\n",
        "- Removes excess whitespace.\n",
        "\n",
        "**Input**: Raw OCR text.\n",
        "**Output**: Clean, high-quality text.\n",
        "**Role**: Data Cleaning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d9d95e2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning text...\n",
            "\n",
            "Doc 0: reduced 41795 -> 41306 chars\n",
            "Doc 1: reduced 27768 -> 27365 chars\n",
            "Doc 2: reduced 10284 -> 10049 chars\n",
            "Doc 3: reduced 86982 -> 86138 chars\n",
            "Doc 4: reduced 150177 -> 148755 chars\n"
          ]
        }
      ],
      "source": [
        "# @title üßπ Clean Text\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'page \\d+ of \\d+', '', text)\n",
        "    text = re.sub(r'page \\d+', '', text)\n",
        "    return text\n",
        "\n",
        "print(\"Cleaning text...\\n\")\n",
        "for doc in documents:\n",
        "    doc['clean_text'] = normalize_text(doc['raw_text'])\n",
        "    print(f\"Doc {doc['doc_id']}: reduced {len(doc['raw_text'])} -> {len(doc['clean_text'])} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5672cb4d",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Step 7: Chunking (Sliding Window)\n",
        "**What it does**:\n",
        "- Splits long documents into smaller segments (Chunks).\n",
        "- Uses **Overlap** to ensure context isn't cut off at the edge.\n",
        "\n",
        "**Input**: Config (Chunk Size=400 chars, Overlap=80 chars).\n",
        "**Output**: List of Chunk objects.\n",
        "**Role**: Granularity Control (preparing text for the Embedding Model).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6d2e4688",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Generated 982 chunks.\n"
          ]
        }
      ],
      "source": [
        "# @title ‚úÇÔ∏è Execute Chunking\n",
        "CHUNK_SIZE = 400\n",
        "CHUNK_OVERLAP = 80\n",
        "\n",
        "chunks = []\n",
        "chunk_counter = 0\n",
        "\n",
        "for doc in documents:\n",
        "    text = doc['clean_text']\n",
        "    for i in range(0, len(text), CHUNK_SIZE - CHUNK_OVERLAP):\n",
        "        chunk_text = text[i : i + CHUNK_SIZE]\n",
        "        if len(chunk_text) < 50: continue # Skip noise\n",
        "        \n",
        "        chunks.append({\n",
        "            \"chunk_id\": chunk_counter,\n",
        "            \"doc_id\": doc['doc_id'],\n",
        "            \"text\": chunk_text,\n",
        "            \"source\": doc['source'],\n",
        "            \"position\": i\n",
        "        })\n",
        "        chunk_counter += 1\n",
        "\n",
        "print(f\"‚úÖ Generated {len(chunks)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c731ab",
      "metadata": {},
      "source": [
        "## üß† Step 8: Load Embedding Model\n",
        "**What it does**:\n",
        "- Loads `sentence-transformers/all-MiniLM-L6-v2`.\n",
        "- This model converts text into 384-dimensional vectors.\n",
        "**Critical**: This MUST match the model used in the Inference Notebook.\n",
        "\n",
        "**Input**: Model Name.\n",
        "**Output**: Loaded Model in memory.\n",
        "**Role**: Neural Encoder Loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "99fc8535",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:53,715 - INFO - Use pytorch device_name: cpu\n",
            "2026-01-28 13:42:53,717 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: sentence-transformers/all-MiniLM-L6-v2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:54,346 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:54,464 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:54,745 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6f9e5561d2f4f1da634f41aa978a7e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:55,184 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:55,474 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:55,749 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77ec04ba9a604a3794ac7d74c3d7e60f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:56,206 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:56,246 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:56,511 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:56,558 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:56,606 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14a3ac58147e4d4db13eddcaae339083",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:56,932 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:56,973 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:57,245 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:57,287 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:57,333 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d38cef17af94ac683e710cb29a3210c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:57,894 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "2026-01-28 13:42:57,896 - WARNING - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "2026-01-28 13:42:58,154 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:42:58,194 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:42:58,244 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0391407139564a218e538f62f5e27084",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:42:58,771 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
            "2026-01-28 13:42:59,108 - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/xet-read-token/c9745ed1d9f207416be6d2e6f8de32d1f16199bf \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e175128039d745b19be4002c26da5aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6fc01e0f3f3436eb75ada895c312b1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "2026-01-28 13:45:34,355 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:34,395 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:34,660 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:34,694 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:34,744 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26b84c950dcb49a0879a90d3b900c52c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:45:35,056 - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "2026-01-28 13:45:35,327 - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:35,593 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/vocab.txt \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:35,630 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/vocab.txt \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:35,684 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/vocab.txt \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ad4b0cd4ae4cb6b7f85bfae025b23d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:45:35,986 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:36,037 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:36,090 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cf23d8a505244da8b5db6d4fbd4223e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:45:36,435 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-01-28 13:45:36,716 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/special_tokens_map.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:36,755 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:36,805 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/special_tokens_map.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6d4cc1b3e7d4c879c58b02e658131b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:45:37,093 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "2026-01-28 13:45:37,474 - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-01-28 13:45:37,512 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "2026-01-28 13:45:37,556 - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18a62a96ca444bc18768fa12bde5b325",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:45:37,875 - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded.\n"
          ]
        }
      ],
      "source": [
        "# @title üß† Load Model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "print(f\"Loading model: {MODEL_NAME}...\")\n",
        "embedding_model = SentenceTransformer(MODEL_NAME)\n",
        "print(\"‚úÖ Model loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929ee4c1",
      "metadata": {},
      "source": [
        "## üî¢ Step 9: Generate Embeddings\n",
        "**What it does**:\n",
        "- Passes all text chunks through the Neural Network.\n",
        "- Returns a matrix of floating point numbers.\n",
        "\n",
        "**Input**: List of text strings.\n",
        "**Output**: Numpy array of shape `(Num_Chunks, 384)`.\n",
        "**Role**: Vectorization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f54561fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding 982 chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcead59271ba47eabee61fd5b9de8cbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Embeddings shape: (982, 384)\n"
          ]
        }
      ],
      "source": [
        "# @title üî¢ Compute Embeddings\n",
        "import numpy as np\n",
        "chunk_texts = [c['text'] for c in chunks]\n",
        "print(f\"Encoding {len(chunk_texts)} chunks...\")\n",
        "embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "embeddings = embeddings.astype(np.float32)\n",
        "print(f\"‚úÖ Embeddings shape: {embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa0c4bc",
      "metadata": {},
      "source": [
        "## üìö Step 10: Create FAISS Index\n",
        "**What it does**:\n",
        "- Creates a structural index optimized for fast L2 (Euclidean) distance search.\n",
        "- Adds the vectors to this index.\n",
        "\n",
        "**Input**: Embeddings Matrix.\n",
        "**Output**: Populated FAISS Index.\n",
        "**Role**: Database Creation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "01cbec16",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-28 13:46:39,075 - INFO - Loading faiss with AVX2 support.\n",
            "2026-01-28 13:46:39,487 - INFO - Successfully loaded faiss with AVX2 support.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ FAISS Index created. Total vectors: 982\n"
          ]
        }
      ],
      "source": [
        "# @title üìö Build Index\n",
        "import faiss\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "print(f\"‚úÖ FAISS Index created. Total vectors: {index.ntotal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309ad650",
      "metadata": {},
      "source": [
        "## üóÇÔ∏è Step 11: Configure Metadata\n",
        "**What it does**:\n",
        "- Creates a \"Sidecar\" dictionary that links every Vector ID back to its original Text and Source File.\n",
        "- FAISS stores numbers; this stores the actual info.\n",
        "\n",
        "**Input**: Chunk list.\n",
        "**Output**: `metadata_store` and `text_store` dictionaries.\n",
        "**Role**: Data Mapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e1744183",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Prepared metadata for 982 items.\n"
          ]
        }
      ],
      "source": [
        "# @title üóÇÔ∏è Prepare Meta Stores\n",
        "metadata_store = {}\n",
        "text_store = {}\n",
        "for i, chunk in enumerate(chunks):\n",
        "    c_id = chunk['chunk_id']\n",
        "    metadata_store[c_id] = { \"doc_id\": chunk['doc_id'], \"source\": chunk['source'], \"position\": chunk['position'] }\n",
        "    text_store[c_id] = chunk['text']\n",
        "print(f\"‚úÖ Prepared metadata for {len(metadata_store)} items.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee1168b",
      "metadata": {},
      "source": [
        "## üíæ Step 12: Save to Disk\n",
        "**What it does**:\n",
        "- Serializes (saves) all artifacts to the `./vector_store` folder.\n",
        "- Zips the folder for easy download.\n",
        "\n",
        "**Input**: Index, Dictionaries, Config.\n",
        "**Output**: `vector_store_backup.zip`.\n",
        "**Role**: Persistence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fa673dcf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All artifacts saved.\n",
            "üì¶ Created 'vector_store_backup.zip' for download.\n"
          ]
        }
      ],
      "source": [
        "# @title üíæ Save & Zip\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "index_path = os.path.join(OUTPUT_DIR, 'index.faiss')\n",
        "metadata_path = os.path.join(OUTPUT_DIR, 'metadata.pkl')\n",
        "texts_path = os.path.join(OUTPUT_DIR, 'texts.pkl')\n",
        "\n",
        "faiss.write_index(index, index_path)\n",
        "with open(metadata_path, 'wb') as f: pickle.dump(metadata_store, f)\n",
        "with open(texts_path, 'wb') as f: pickle.dump(text_store, f)\n",
        "\n",
        "print(\"‚úÖ All artifacts saved.\")\n",
        "shutil.make_archive('vector_store_backup', 'zip', OUTPUT_DIR)\n",
        "print(\"üì¶ Created 'vector_store_backup.zip' for download.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
