# ğŸ¥ Adaptive RAG System - Production Ready

A production-grade, client-server architecture for the **Adaptive RAG Medical Guideline Assistant**.

## ğŸ“š Architecture Overview

```
adaptiverag/
â”œâ”€â”€ client/          # Next.js 14 Frontend
â”‚   â”œâ”€â”€ src/app/     # React components & pages
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ server/          # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/     # REST endpoints
â”‚   â”‚   â”œâ”€â”€ core/    # LLM, embeddings, vector store
â”‚   â”‚   â””â”€â”€ pipeline/ # 10-phase RAG logic
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Documents/       # Source PDFs (medical guidelines)
â”œâ”€â”€ vector_store/    # FAISS index (generated)
â””â”€â”€ docker-compose.yml
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- A Groq API key (or OpenAI-compatible LLM API)

### 1. Setup Backend

```bash
cd server

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Copy and configure environment
cp .env.example .env
# Edit .env and add your LLM_API_KEY

# Copy vector store
xcopy ..\vector_store vector_store /E /I  # Windows
# cp -r ../vector_store ./vector_store  # Linux/Mac

# Start server
uvicorn app.main:app --reload --port 8000
```

### 2. Setup Frontend

```bash
cd client

# Install dependencies
npm install

# Start development server
npm run dev
```

### 3. Access the Application
- **Frontend**: http://localhost:3000
- **Backend API Docs**: http://localhost:8000/docs

---

## ğŸ”„ The 10-Phase Adaptive Pipeline

Every query passes through this rigorous verification pipeline:

| Phase | Name | Purpose |
|-------|------|---------|
| 1 | Query Analyzer | Understand intent, category, and tone |
| 2 | Relevance Checker | Filter out-of-domain queries |
| 3 | Safety Validator | Verify rewrite preserves meaning |
| 4 | Central Control | Decide query strategy |
| 5 | Retriever | FAISS vector search + KB coverage guard |
| 6 | Retrieval Grader | Verify document quality |
| 7 | Generator | Tone-aware answer generation |
| 8 | Hallucination Checker | Fact-check against sources |
| 9 | Final Checker | Verify answer addresses query |
| 10 | Orchestrator | Retry loop with fallback |

---

## ğŸ³ Docker Deployment

```bash
docker-compose up --build
```

This starts:
- Backend on `http://localhost:8000`
- Frontend on `http://localhost:3000`

---

## ğŸ“ Original Notebooks (Reference)

The original Jupyter notebooks are preserved for reference:
- `Adaptive__Rag.ipynb` - Interactive demo with Gradio
- `offline_indexing_pipeline.ipynb` - Document indexing pipeline

---

## ğŸ”§ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `LLM_API_KEY` | Your Groq/OpenAI API key | (required) |
| `LLM_BASE_URL` | LLM API endpoint | `https://api.groq.com/openai/v1` |
| `LLM_MODEL_NAME` | Model to use | `llama-3.3-70b-versatile` |
| `VECTOR_STORE_DIR` | Path to FAISS index | `./vector_store` |

---

## ğŸ“ License

This project is for educational purposes in antimicrobial stewardship.
