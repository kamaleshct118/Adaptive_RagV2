"""
Phase 10: Orchestrator Loop (Main Pipeline)
Coordinates all phases of the Adaptive RAG system with retry logic.
"""
import traceback
from typing import Optional
from dataclasses import dataclass, field
from ..config import get_settings
from .query_analyzer import analyze_query
from .relevance_checker import check_relevance
from .safety_validator import validate_rewrite, decide_query_strategy
from .retriever import retrieve_documents, is_kb_covering
from .retrieval_grader import grade_retrieval
from .generator import generate_answer
from .hallucination_checker import check_hallucination
from .final_checker import check_answer_relevance
from .fallback_agent import generate_fallback_response


@dataclass
class PipelineResult:
    """Result from the RAG pipeline execution."""
    answer: str
    category: str = "General"
    tone: str = "Simplified Educational"
    logs: list[str] = field(default_factory=list)
    success: bool = True
    is_fallback: bool = False


def query_reconstructor_pipeline(
    user_query: str,
    feedback_reason: Optional[str] = None
) -> Optional[dict]:
    """
    Phase 4: Central Control Node
    Ties Phases 1, 2, and 3 together.
    
    Args:
        user_query: The user's query
        feedback_reason: Optional feedback from previous retry
        
    Returns:
        Reconstruction result dict or None if failed
    """
    # 1. Analyze
    q_in = f"{user_query} (Fix: {feedback_reason})" if feedback_reason else user_query
    analysis = analyze_query(q_in)
    
    if not analysis:
        return None
    
    # 2. Relevance Check
    is_rel, rel_msg = check_relevance(user_query, analysis)
    if not is_rel:
        return {"is_relevant": False, "logs": [f"Irrelevant: {rel_msg}"]}
    
    # 3. Validate Rewrite
    rewritten = analysis.get('rewritten_query', user_query)
    validation = validate_rewrite(user_query, rewritten)
    
    # 4. Decide Strategy
    final_q, note = decide_query_strategy(user_query, rewritten, validation)
    
    return {
        "is_relevant": True,
        "final_query": final_q,
        "category": analysis.get('category', 'General'),
        "answer_tone": analysis.get('answer_tone', 'Simplified Educational'),
        "logs": [
            f"Category: {analysis.get('category')}",
            f"Tone: {analysis.get('answer_tone')}",
            f"Strategy: {note}",
            f"Final Query: {final_q}"
        ]
    }


def run_adaptive_rag_pipeline(user_query: str) -> PipelineResult:
    """
    Main orchestrator for the Adaptive RAG pipeline.
    
    Executes the full 10-phase pipeline with retry logic:
    1. Query Analysis & Restructuring
    2. Relevance Check
    3. Safety Validation
    4. Central Control
    5. Retrieval
    6. Retrieval Grading
    7. Answer Generation
    8. Hallucination Check
    9. Final Relevance Check
    10. Orchestration Loop
    
    Args:
        user_query: The user's question
        
    Returns:
        PipelineResult with answer, metadata, and logs
    """
    settings = get_settings()
    
    try:
        max_retries = settings.max_pipeline_retries
        attempt = 0
        logs = []
        feedback_reason = None
        recon = None
        
        while attempt < max_retries:
            attempt += 1
            logs.append(f"\n--- ðŸ”„ Cycle {attempt} ---")
            
            # 1. Reconstruct Query
            recon = query_reconstructor_pipeline(user_query, feedback_reason)
            
            if recon is None:
                logs.append("âŒ LLM Service Unavailable (Rate Limit or Error).")
                return PipelineResult(
                    answer="Unable to process query due to high server load. Please try again in 1 minute.",
                    logs=logs,
                    success=False
                )
            
            if not recon or not recon.get('is_relevant'):
                if attempt == 1:
                    logs.extend(recon.get('logs', []))
                    return PipelineResult(
                        answer="I can only answer relevant questions.",
                        logs=logs,
                        success=False
                    )
                else:
                    logs.append("âš ï¸ Re-evaluated as locally irrelevant. Continuing retry loop...")
                    continue
            
            logs.extend(recon['logs'])
            
            # 2. Retrieve Documents
            contexts = retrieve_documents(recon['final_query'])
            
            # 3. KB Coverage Guard
            if not is_kb_covering(recon['final_query'], contexts):
                logs.append("âš ï¸ KB Coverage Failure (Weak Match). Retrying...")
                feedback_reason = "Knowledge Base has no strong match for this specific medical subdomain."
                continue
            
            # 4. Grade Retrieval
            if grade_retrieval(recon['final_query'], contexts) == "BAD":
                logs.append("âš ï¸ Retrieval BAD. Retrying...")
                feedback_reason = "Retrieved documents were irrelevant."
                continue
            
            # 5. Generate Answer
            answer = generate_answer(
                recon['final_query'],
                contexts,
                recon['category'],
                recon['answer_tone']
            )
            
            # 6. Check Hallucination
            if check_hallucination(answer, contexts) == "YES":
                logs.append("âš ï¸ Hallucination detected. Regenerating...")
                answer = generate_answer(
                    recon['final_query'],
                    contexts,
                    recon['category'],
                    recon['answer_tone']
                )
            
            # 7. Check Final Relevance
            if check_answer_relevance(answer, user_query) == "NO":
                logs.append("âš ï¸ Answer not relevant. Retrying...")
                feedback_reason = "Answer missed intent."
                continue
            
            logs.append("âœ… Success.")
            return PipelineResult(
                answer=answer,
                category=recon['category'],
                tone=recon['answer_tone'],
                logs=logs,
                success=True
            )
        
        # Max retries exhausted - use fallback
        logs.append("\nâš ï¸ Max retries exhausted. Retrieving Fallback...")
        
        current_category = recon.get('category', 'General') if recon else 'General'
        current_tone = recon.get('answer_tone', 'Simplified Educational') if recon else 'Simplified Educational'
        
        fallback_ans = generate_fallback_response(user_query, current_category, current_tone)
        
        if fallback_ans:
            logs.append("âœ… Fallback Generated.")
            return PipelineResult(
                answer=fallback_ans,
                category=current_category,
                tone=current_tone,
                logs=logs,
                success=True,
                is_fallback=True
            )
        
        return PipelineResult(
            answer="âŒ Failed to find a valid answer and fallback generation failed.",
            logs=logs,
            success=False
        )
        
    except Exception as e:
        err_msg = f"âŒ SYSTEM CRASH: {str(e)}"
        tb = traceback.format_exc().splitlines()
        return PipelineResult(
            answer=err_msg,
            logs=tb,
            success=False
        )
